---
title: "Point Weights"
author: "steppe"
output:
  word_document: default
  pdf_document: default
always_allow_html: true
---
This AIM study was designed in order to both maximize the environmental habitats which it represented across the field office, and be able to inform our understanding of high priority management areas. The first of these goals, makes the design 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)
knitr::opts_chunk$set(dpi = 300) 
knitr::opts_chunk$set(message = F)
knitr::opts_chunk$set(warning = F)
```

```{r Load libraries, warning = F, message = F, echo = F}
library(tidyverse)
library(sf)
library(terra)
library(spsurvey)
source('functions.R')
```

```{r}
p2d <- '../data/raw'

plot_status <- read.csv(file.path(p2d, list.files(path = p2d, pattern = "summary.csv")))  %>% 
  mutate(across(.cols = everything(), ~ str_to_lower(.))) %>% 
  
  # humans are humans and typos are an expression of humanity. also  add a 
  # factor levels which we arrange by and slice the top from . 
  mutate(
    Plot.Status = str_trim(Plot.Status, side = "both"),
  #  Plot.Status = str_replace(Plot.Status, 'rejected', 'not_sampled'),
    Plot.Status = str_replace(Plot.Status, " ", "_"),
    psF = factor(Plot.Status, levels = c('sampled', 'not_sampled', 'rejected'))
    ) %>%  
  
  # some numbers are missing leading zereos
  separate(Plot.ID, into = c('stratum', 'id'), sep = '-') %>% 
  mutate(id = str_pad(id, 3, pad = "0")) %>% 
  
  # group up - and take that 'sampled' from the top - if present
  unite('Plot.ID', stratum:id, sep = "-", remove = F) %>% 
  group_by(Plot.ID) %>% 
  arrange(psF) 

# some plots were not sampled in one year, but subsequently sampled
status_check <- plot_status %>% # we want to ensure all of these plots are returned as sampled. 
  mutate(grp_n = n()) %>% 
  filter(grp_n >= 2, Plot.Status == 'sampled')

plot_status <- plot_status %>% 
  slice_head(n = 1) %>% 
  ungroup()

# inner_join(plot_status, status_check, by = 'Plot.ID') # take a look for yourself, all good. 

# it turns out some oversamples from the original design were not populated over to the yearly tracking 
# sheets. We can note there status as not_sampled here. 
plot_status <- plot_status %>% 
  mutate(across(.cols = Plot.ID:stratum, ~ str_to_upper(.x)))
pts <- st_read(
  '/media/sagesteppe/ExternalHD/aimDB/data/raw/AIM_Sample_Design/AIM_Design_Stratification.shp',
                quiet = T) %>% 
  left_join(., plot_status, by = c('PLOTID' = 'Plot.ID')) %>% 
  select(-Panel) %>%  
  separate(PLOTID, into = c('stratum', 'id'), sep = '-', remove = F) %>% 
  mutate(across(Plot.Status:psF, ~ replace_na(.x, 'not_sampled'))) %>%  
  # some over samples were not completed
  select(Plot.ID = PLOTID, stratum, id, Panel = PANEL, Plot.Status, psF, xcoord, ycoord, geometry)
  
plot_status <- pts %>% 
  select(colnames(plot_status)) %>% 
  st_drop_geometry()

plot_summary <- plot_status %>% 
  group_by(stratum, Plot.Status) %>% 
  summarise(n = n())  %>% 
  ungroup(Plot.Status) %>% 
  mutate(total = sum(n)) %>% 
  pivot_longer(n:total, values_to = 'Number') %>% 
  mutate(Plot.Status = if_else(name == 'total', 'total', Plot.Status)) %>% 
  select(-name) %>% 
  group_by(stratum, Plot.Status) %>% 
  sample_n(1)

rm(status_check)

# format table for printing
plot_summary <- plot_summary %>% 
  pivot_wider(values_from = Number, names_from = Plot.Status) %>% 
  mutate(stratum = str_to_upper(stratum)) %>% 
  mutate(across(.cols = everything(), ~ replace_na(.x, 0))) %>% 
  rename_with(., ~ str_to_sentence(.))

# DERIVE THE VALUES FOR BOTH TOTAL AREA AND AREAS IN ACRES

r <- read.csv(file.path(p2d, 'UFO_strata_areas.csv')) %>% 
  mutate(ProportionalArea = Cells/sum(Cells)) %>% 
  select(Stratum, Code, ProportionalArea, Acres)

deSS <- data.frame( # desired sample size per stratum over live of sample design
  'Stratum' = c("AS", "GR", "MC", "MMS", "OT" , "PJ", "PP", "RI", "SD" , "SS" ), 
  'DesiredSS' = c(5, 5, 15, 25, 5, 25, 5, 15, 75, 80),
  'PropTarget' = c(0.01, 0.02, 0.05, 0.1, 0.01, 0.12, 0.01, 0.05, 0.3, 0.33)
) 

OriginalWeights <- left_join(plot_summary, r, by = c('Stratum' = 'Code')) %>% 
  left_join(., deSS, by = 'Stratum') %>% 
  select(StratumName = Stratum.y, Stratum, Total,  NotSampled = Not_sampled, Rejected, Sampled, 
          DesiredSS, PropArea = ProportionalArea, PropTarget, Acres) %>% 
  mutate(ApproxStWgt = Acres / (DesiredSS/5))

write.csv(OriginalWeights, '../data/processed/OriginalWeightsSampleDesign.csv', row.names = F)

OriginalWeights %>% 
  mutate(PropArea = round(PropArea, 3)) %>% 
  mutate(across(.cols = c(Acres, ApproxStWgt),  round)) %>% 
  arrange(-Acres) %>% 
  ungroup() %>% 
  select(StratumName, Acres, PropArea, PropTarget, DesiredSS, ApproxStWgt) %>% 
  knitr::kable(., digits = 2, format.args = list(big.mark = ","), 
               col.names = c('Stratum', 'Total Area (acres)', 'Prop. Area', 'Prop. Site', 'No. Sites', 'Plot Wt.'), 
               align = c("c", rep('r', times = (ncol(.) - 1)))) 
  
rm(r, plot_summary, plot_status)
```


Design Weights 

Under a Simple Random Sample, wherein each stratum would be un-weighed

$$\pi_{i} = n/N$$

+  $\pi_{i}$ is the inclusion probability of each individual, i.e. the probability of a site being selected 
+  $n$ sample size, e.g. the number of plots 
+  $N$ population size, e.g. the target is geographic size of the BLM field office 


Under a weighed design, wherein each stratum has an associated weight e.g. based on it's heterogeneity

$$W_{i} = 1/ \pi_{i}$$

+ $\pi_{i}$ is the inclusion probability of each individual, i.e. the probability of a site being selected 
+ $W_{i}$ is the weight associated with each site 


```{r Adjust the Sample Point Weights across entire Field Office}

Full_newWghts <- plotWeigher(OriginalWeights, pts)

Full_newWghts %>% 
  mutate(across(TotalAcres:WgtAcres, ~ round(.x))) %>% 
  mutate(across(PlotsSampled:PlotsRejected, ~ replace_na(.x, 0))) %>% 
  arrange(-TotalAcres) %>% 
  select(Stratum, PropInference, TotalAcres:WgtAcres, PlotsSampled, PlotsRejected) %>% 
  knitr::kable(., digits = 2, format.args = list(big.mark = ","),
               col.names = c('Stratum', 'Inference Prop.', 'Area (acres)', 'Area to Infer', 'Plot Wt.', 'Sampled', 'Rejected'),
               align = c("c", rep('r', times = (ncol(.) - 1))))

rm(OriginalWeights)
```


The reporting units of Areas of Critical Environmental Concern (ACEC's), and Wilderness Study Areas (WSA), have different management objectives relative to the remaining BLM administered surface area. These areas are intended to have " ... greater than 80 percent vegetation communities  ... ". These areas were not intensified units within the original sample design, rather we split them out here using the original point draw for the field office. Here we calculate the initial sample weights for them using the same approach as for the remainder of BLM land, i.e. the acreage of each stratum is weighed against a targeted proportion of sites in the region. As our sample design was initiated and completed during a period of drought (See...), we dismiss the possibilities of making temporal comparisons across the sample panels. Accordingly, we have strata within these management units which: do not have a point per year panel (i.e. cannot be sampled each year). Subsequently, we do not have the initial ability to infer across the entire acreage of each stratum within them. 



```{r Point weights for ACEC and WSA}

spatial_products <- '/media/sagesteppe/ExternalHD/UFO_cartography'
design_rast <- '/media/sagesteppe/ExternalHD/UFO_AIM_Design_Stratification/processed'
lookup_table <- read.csv(file.path(design_rast, 'UFO_strata_areas.csv')) %>% 
  select(RasterValue, Code)

uFO <- st_read(file.path(spatial_products, 
                         'BLM_CO_Grazing_Allotments/gra_allot_poly.shp'), quiet = T)
acecs <- st_read(file.path(spatial_products, 'BLM_CO_ACEC/acec_desig_poly.shp'), 
                 quiet = T) %>%  
  st_intersection(uFO, .) %>% 
  select(NAME = ACEC_NAME) %>% 
  mutate(TYPE = 'ACEC')
wsa <- st_read(file.path(spatial_products, 'BLM_CO_WSA/nlcs_wsa_poly.shp'), 
               quiet = T) %>% 
  st_intersection(uFO, .) %>% 
  select(NAME = NLCS_NAME) %>% 
  mutate(TYPE = 'WSA')

wsAcec <- bind_rows(acecs, wsa) %>% 
  mutate(ID = 1:n(), .before = 1)

rm(acecs, wsa)

# identify all points which fell in the focal areas
wsAcec_pts <- pts[unlist(st_intersects(wsAcec, st_transform(pts, st_crs(wsAcec)))),]

# identify the cover of each stratum in the focal area
wsaSpat <- vect(wsAcec) 
wsAcec_areas <- terra::expanse(wsaSpat, unit = 'ha') * 2.47105 # conversion to acres
TotalFocalArea <- sum(wsAcec_areas)
wsAcec_areas <- bind_cols(wsAcec, Total_Area =  wsAcec_areas, TotalFocalArea = TotalFocalArea)

strat_raster <- terra::rast(file.path(design_rast, 'UFO_Strata_reclass_30m.tif'))
wsaSpat <- project(wsaSpat, crs(strat_raster))

raster_cells <- extract(strat_raster, wsaSpat) %>% 
  group_by(ID, BPS_CODE) %>% 
  count() %>% 
  ungroup(BPS_CODE) %>% 
  mutate(PropArea = n/sum(n))  %>% # seems off. 
  left_join(., lookup_table, by = c('BPS_CODE' = 'RasterValue'))

rm(wsaSpat, TotalFocalArea)

wsAcec_areas <- left_join(wsAcec_areas, raster_cells) %>% 
  mutate(Area = Total_Area * PropArea)  %>% 
  select(ID, NAME, TYPE, Total_Area, Code, PropArea, Area, TotalFocalArea)

wsAcec_area_summary <- wsAcec_areas %>% 
  ungroup() %>% 
  group_by(Code) %>% 
  mutate(TotalArea = sum(Area)) %>% 
  ungroup() %>% 
  distinct(Code, .keep_all = T) %>% 
  select(Stratum = Code, TotalArea, PropArea, TotalFocalArea) %>%
  mutate(PropArea = TotalArea/sum(TotalArea)) %>% 
  st_drop_geometry()

base_wsAcec_pts <- wsAcec_pts %>% 
  filter(str_detect(Panel, 'OverSample', negate = T))

# need to calculate the desired sites per stratum as function of plot weight. 
wsAcec_area_summary <- wsAcec_area_summary %>% 
  left_join(., deSS, by = 'Stratum') %>%  # desired ss total_area / wsAcec
  mutate(DesiredSS = round(DesiredSS * (nrow(base_wsAcec_pts)/255))) %>% 
  drop_na()

wsAcec_pt_draw <- wsAcec_pts %>% 
  group_by(stratum, Plot.Status) %>% 
  count() %>% 
  st_drop_geometry() %>% 
  pivot_wider(id_cols = stratum, names_from = Plot.Status, values_from = n, 
              values_fill = 0) %>% 
  rowwise() %>% 
  mutate(total = sum(across(not_sampled:sampled)), .before = 'not_sampled')

wsAcec_OriginalWeights <- left_join(wsAcec_area_summary, wsAcec_pt_draw,
                                    by = c('Stratum' = 'stratum')) %>% 
  select(Stratum, Total = total, NotSampled = not_sampled, Rejected = rejected, 
         Sampled = sampled, DesiredSS, PropArea, PropTarget, Acres =  TotalArea) %>% 
  mutate(ApproxStWgt =  if_else(DesiredSS >= 5, (Acres/DesiredSS) * 5, (DesiredSS/5) * Acres))

wsAcec_OriginalWeights <- drop_na(wsAcec_OriginalWeights)

plotWeigher(wsAcec_OriginalWeights, wsAcec_pts)


rm(raster_cells, wsaSpat, wsAcec)
```











```{r Point weights for the National Monument writeups}

monuments <- st_read(file.path(spatial_products, 'BLM_CO_NM_NCA/nlcs_nm_nca_poly.shp'), 
                 quiet = T) %>%  st_intersection(uFO, .) %>% 
  group_by(NLCS_NAME) %>% 
  st_collection_extract("POLYGON")  %>%  # there are these funny points
  summarize(geometry = st_union(geometry)) 

mnmt_pts <- pts[unlist(st_intersects(monuments, st_transform(pts, st_crs(monuments)))),]


```












```{r}

# Weights under plots re-classified into realized stratum

pps <- '/media/sagesteppe/ExternalHD/plot_post_stratification/data'

classified_Vplots <- read.csv(
  file.path(pps, 'processed/UFO_Veg_monitoring_CLASSIFIED.csv')) %>% 
  drop_na() %>% 
  sf::st_as_sf(coords = c(x = 'Longitude',  y = 'Latitude' ), crs = 4326)%>% 
  sf::st_transform(26912) %>% 
  sf::st_buffer(55)

plot_status <- read.csv(file.path(p2d, list.files(path = p2d, pattern = "summary.csv")))[307:409,] 
classified_Vplots2022 <- read.csv( # but this includes rejected plots... 
  file.path(pps, 'processed', 'UFO_2022_AIM_CLASSIFIED.csv')) 

pps <- '/media/sagesteppe/ExternalHD/aimDB/data/raw/AIM_Sample_Design'
a <- sf::st_read(file.path(pps, 'AIM_Design_Stratification.shp'), quiet = T) %>% 
  sf::st_transform(26912) %>% 
  sf::st_buffer(55)

d <- sf::st_join(classified_Vplots, a, left = F)

```